{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar  9 17:10:47 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |\n",
      "| 41%   43C    P8    14W / 260W |    380MiB / 11264MiB |     21%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1136      G   /usr/lib/xorg/Xorg                 23MiB |\n",
      "|    0   N/A  N/A      2154      G   /usr/lib/xorg/Xorg                 92MiB |\n",
      "|    0   N/A  N/A      2281      G   /usr/bin/gnome-shell              114MiB |\n",
      "|    0   N/A  N/A      2376      G   ...mviewer/tv_bin/TeamViewer       13MiB |\n",
      "|    0   N/A  N/A      4549      G   /usr/lib/firefox/firefox          123MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/arthurflor23/handwritten-text-recognition/blob/master/src/tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gP-v0E_S-mQP"
   },
   "source": [
    "<img src=\"https://github.com/arthurflor23/handwritten-text-recognition/blob/master/doc/image/header.png?raw=true\" />\n",
    "\n",
    "# Handwritten Text Recognition using TensorFlow 2.x\n",
    "\n",
    "This tutorial shows how you can use the project [Handwritten Text Recognition](https://github.com/arthurflor23/handwritten-text-recognition) in your Google Colab.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMty1YwuWHpN"
   },
   "source": [
    "## 1 Localhost Environment\n",
    "\n",
    "We'll make sure you have the project in your Google Drive with the datasets in HDF5. If you already have structured files in the cloud, skip this step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39blvPTPQJpt"
   },
   "source": [
    "### 1.1 Datasets\n",
    "\n",
    "The datasets that you can use:\n",
    "\n",
    "a. [Bentham](http://www.transcriptorium.eu/~tsdata/)\n",
    "\n",
    "b. [IAM](http://www.fki.inf.unibe.ch/databases/iam-handwriting-database)\n",
    "\n",
    "c. [Rimes](http://www.a2ialab.com/doku.php?id=rimes_database:start)\n",
    "\n",
    "d. [Saint Gall](https://fki.tic.heia-fr.ch/databases/saint-gall-database)\n",
    "\n",
    "e. [Washington](https://fki.tic.heia-fr.ch/databases/washington-database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVBGMLifWQwl"
   },
   "source": [
    "### 1.2 Raw folder\n",
    "\n",
    "On localhost, download the code project from GitHub and extract the chosen dataset (or all if you prefer) in the **raw** folder. Don't change anything of the structure of the dataset, since the scripts were made from the **original structure** of them. Your project directory will be like this:\n",
    "\n",
    "```\n",
    ".\n",
    "├── raw\n",
    "│   ├── bentham\n",
    "│   │   ├── BenthamDatasetR0-GT\n",
    "│   │   └── BenthamDatasetR0-Images\n",
    "│   ├── iam\n",
    "│   │   ├── ascii\n",
    "│   │   ├── forms\n",
    "│   │   ├── largeWriterIndependentTextLineRecognitionTask\n",
    "│   │   ├── lines\n",
    "│   │   └── xml\n",
    "│   ├── rimes\n",
    "│   │   ├── eval_2011\n",
    "│   │   ├── eval_2011_annotated.xml\n",
    "│   │   ├── training_2011\n",
    "│   │   └── training_2011.xml\n",
    "│   ├── saintgall\n",
    "│   │   ├── data\n",
    "│   │   ├── ground_truth\n",
    "│   │   ├── README.txt\n",
    "│   │   └── sets\n",
    "│   └── washington\n",
    "│       ├── data\n",
    "│       ├── ground_truth\n",
    "│       ├── README.txt\n",
    "│       └── sets\n",
    "└── src\n",
    "    ├── data\n",
    "    │   ├── evaluation.py\n",
    "    │   ├── generator.py\n",
    "    │   ├── preproc.py\n",
    "    │   ├── reader.py\n",
    "    │   ├── similar_error_analysis.py\n",
    "    ├── main.py\n",
    "    ├── network\n",
    "    │   ├── architecture.py\n",
    "    │   ├── layers.py\n",
    "    │   ├── model.py\n",
    "    └── tutorial.ipynb\n",
    "\n",
    "```\n",
    "\n",
    "After that, create virtual environment and install the dependencies with python 3 and pip:\n",
    "\n",
    "> ```python -m venv .venv && source .venv/bin/activate```\n",
    "\n",
    "> ```pip install -r requirements.txt```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WyLRbAwsWSYA"
   },
   "source": [
    "### 1.3 HDF5 files\n",
    "\n",
    "Now, you'll run the *transform* function from **main.py**. For this, execute on **src** folder:\n",
    "\n",
    "> ```python main.py --source=<DATASET_NAME> --transform```\n",
    "\n",
    "Your data will be preprocess and encode, creating and saving in the **data** folder. Now your project directory will be like this:\n",
    "\n",
    "\n",
    "```\n",
    ".\n",
    "├── data\n",
    "│   ├── bentham.hdf5\n",
    "│   ├── iam.hdf5\n",
    "│   ├── rimes.hdf5\n",
    "│   ├── saintgall.hdf5\n",
    "│   └── washington.hdf5\n",
    "├── raw\n",
    "│   ├── bentham\n",
    "│   │   ├── BenthamDatasetR0-GT\n",
    "│   │   └── BenthamDatasetR0-Images\n",
    "│   ├── iam\n",
    "│   │   ├── ascii\n",
    "│   │   ├── forms\n",
    "│   │   ├── largeWriterIndependentTextLineRecognitionTask\n",
    "│   │   ├── lines\n",
    "│   │   └── xml\n",
    "│   ├── rimes\n",
    "│   │   ├── eval_2011\n",
    "│   │   ├── eval_2011_annotated.xml\n",
    "│   │   ├── training_2011\n",
    "│   │   └── training_2011.xml\n",
    "│   ├── saintgall\n",
    "│   │   ├── data\n",
    "│   │   ├── ground_truth\n",
    "│   │   ├── README.txt\n",
    "│   │   └── sets\n",
    "│   └── washington\n",
    "│       ├── data\n",
    "│       ├── ground_truth\n",
    "│       ├── README.txt\n",
    "│       └── sets\n",
    "└── src\n",
    "    ├── data\n",
    "    │   ├── evaluation.py\n",
    "    │   ├── generator.py\n",
    "    │   ├── preproc.py\n",
    "    │   ├── reader.py\n",
    "    │   ├── similar_error_analysis.py\n",
    "    ├── main.py\n",
    "    ├── network\n",
    "    │   ├── architecture.py\n",
    "    │   ├── layers.py\n",
    "    │   ├── model.py\n",
    "    └── tutorial.ipynb\n",
    "\n",
    "```\n",
    "\n",
    "Then upload the **data** and **src** folders in the same directory in your Google Drive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jydsAcWgWVth"
   },
   "source": [
    "## 2 Google Drive Environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wk3e7YJiXzSl"
   },
   "source": [
    "### 2.1 TensorFlow 2.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7twXyNGXtbJ"
   },
   "source": [
    "Make sure the jupyter notebook is using GPU mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mHw4tODULT1Z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce RTX 2080 Ti (UUID: GPU-423511d7-6c6c-ac32-4ede-86c055221433)\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "FMg-B5PH9h3r"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "if device_name != \"/device:GPU:0\":\n",
    "    raise SystemError(\"GPU device not found\")\n",
    "\n",
    "print(\"Found GPU at: {}\".format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyMv5wyDXxqc"
   },
   "source": [
    "### 2.2 Google Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P5gj6qwoX9W3"
   },
   "source": [
    "Mount your Google Drive partition.\n",
    "\n",
    "**Note:** *\\\"Colab Notebooks/handwritten-text-recognition/src/\\\"* was the directory where you put the project folders, specifically the **src** folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ACQn1iBF9k9O"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"./gdrive\", force_remount=True)\n",
    "\n",
    "%cd \"./gdrive/My Drive/Colab Notebooks/handwritten-text-recognition/src/\"\n",
    "!ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YwogUA8RZAyp"
   },
   "source": [
    "After mount, you can see the list os files in the project folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-fj7fSngY1IX"
   },
   "source": [
    "## 3 Set Python Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6Q4cOlWhNl3"
   },
   "source": [
    "### 3.1 Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wvqL2Eq5ZUc7"
   },
   "source": [
    "First, let's define our environment variables.\n",
    "\n",
    "Set the main configuration parameters, like input size, batch size, number of epochs and list of characters. This make compatible with **main.py** and jupyter notebook:\n",
    "\n",
    "* **dataset**: \"bentham\", \"iam\", \"rimes\", \"saintgall\", \"washington\"\n",
    "\n",
    "* **arch**: network to run: \"bluche\", \"puigcerver\", \"flor\"\n",
    "\n",
    "* **epochs**: number of epochs\n",
    "\n",
    "* **batch_size**: number size of the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_Qpr3drnGMWS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/images/data'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from data import preproc as pp\n",
    "\n",
    "EPOCHS = 1000\n",
    "BATCH_SIZE = 16\n",
    "ARCH = \"flor\"\n",
    "\n",
    "IMG_SIZE = (1642,6986, 1)\n",
    "DATA_ROOT_PATH = \"../data\"\n",
    "IMAGES_PATH = os.path.join(DATA_ROOT_PATH, \"images\", \"data\")\n",
    "IMAGES_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95381\n"
     ]
    }
   ],
   "source": [
    "maxh=0\n",
    "maxw=0\n",
    "z=0\n",
    "for i in os.listdir(IMAGES_PATH):\n",
    "    l=os.listdir(IMAGES_PATH+\"/\"+i)\n",
    "    for j in l:\n",
    "        if \"py\" not in j:\n",
    "            for k in os.listdir(IMAGES_PATH+\"/\"+i+\"/\"+j):\n",
    "                if \"jpg\" in k:\n",
    "                    z=z+1\n",
    "    \n",
    "        \n",
    "        \n",
    "\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = None\n",
    "\n",
    "with open(os.path.join(DATA_ROOT_PATH, \"hindi_vocab.txt\")) as f:\n",
    "  vocab = f.readlines()\n",
    "\n",
    "idx_to_vocab = {i:value.strip() for i, value in enumerate(vocab)}\n",
    "vocab_to_idx = {value:key for key, value in idx_to_vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=idx_to_vocab[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'वार्ष्णेय'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "व\n",
      "ा\n",
      "र\n",
      "्\n",
      "ष\n",
      "्\n",
      "ण\n",
      "े\n",
      "य\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(s)):\n",
    "    print(s[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = None\n",
    "\n",
    "with open(os.path.join(DATA_ROOT_PATH, \"new_train.txt\"), encoding=\"latin1\") as f:\n",
    "  train_data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HindiSeg/train/10/259/1.jpg 10800\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = None\n",
    "\n",
    "with open(os.path.join(DATA_ROOT_PATH, \"new_val.txt\"), encoding=\"latin1\") as f:\n",
    "  valid_data = f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BFextshOhTKr"
   },
   "source": [
    "### 3.2 DataGenerator Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KfZ1mfvsanu1"
   },
   "source": [
    "The second class is **DataGenerator()**, responsible for:\n",
    "\n",
    "* Load the dataset partitions (train, valid, test);\n",
    "\n",
    "* Manager batchs for train/validation/test process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "8k9vpNzMIAi2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 22:36:42.670179: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-06 22:36:43.920980: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/shashank/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-03-06 22:36:43.921150: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/shashank/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-03-06 22:36:43.921165: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import tensorflow as tf\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "class DataGen(tf.keras.utils.Sequence):\n",
    "    def __init__(self, data, img_size, batch_size, mode=\"TRAIN\"):\n",
    "        self.data = data\n",
    "        self.img_size = img_size\n",
    "        self.batch_size = batch_size\n",
    "        self.mode = mode\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        start = i * self.batch_size\n",
    "        end = (i+1) * self.batch_size\n",
    "        \n",
    "        batch_images = np.zeros((self.batch_size, self.img_size[0], self.img_size[1], 1))\n",
    "        batch_labels = np.zeros((self.batch_size, 1))\n",
    "        \n",
    "        for ii, df_index in enumerate(range(start, end)):\n",
    "            curr_data = self.data[ii].split()\n",
    "            curr_img_path = curr_data[0]\n",
    "            curr_label = vocab_to_idx[curr_data[1]]\n",
    "\n",
    "            curr_img_path = \"/\".join(curr_img_path.split(\"/\")[2:])\n",
    "            curr_img_path = os.path.join(IMAGES_PATH, curr_img_path)\n",
    "\n",
    "            curr_img = Image.open(curr_img_path)\n",
    "            curr_img = ImageOps.grayscale(curr_img)\n",
    "            curr_img = img_to_array(curr_img)\n",
    "            img_shape = curr_img.shape\n",
    "            \n",
    "            curr_img = tf.image.resize(curr_img, (self.img_size[0], self.img_size[1]), method=\"nearest\")\n",
    "            curr_img = curr_img.numpy().reshape((self.img_size[0], self.img_size[1]))\n",
    "            curr_img = pp.preprocess(curr_img_path, self.img_size)\n",
    "            batch_images[ii, :, :, 0] = curr_img / 255.\n",
    "            batch_labels[ii, :] = curr_label\n",
    "                    \n",
    "        if self.mode == \"TRAIN\":\n",
    "          return batch_images, batch_labels\n",
    "        else:\n",
    "          return batch_images, batch_labels\n",
    "        \n",
    "    def __len__(self):\n",
    "      return len(self.data) // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = DataGen(train_data, IMG_SIZE, 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 22:36:53.891228: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-06 22:36:53.967913: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-06 22:36:53.968265: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-06 22:36:53.969829: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-06 22:36:53.971094: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-06 22:36:53.971398: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-06 22:36:53.971641: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-06 22:36:55.157219: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-06 22:36:55.157544: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-06 22:36:55.157787: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-06 22:36:55.157984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 107 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2023-03-06 22:36:55.176768: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:735] failed to allocate 107.81M (113049600 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8, 1642, 6986, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_datagen))[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-OdgNLK0hYAA"
   },
   "source": [
    "### 3.3 HTRModel Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jHktk8AFcnKy"
   },
   "source": [
    "The third class is **HTRModel()**, was developed to be easy to use and to abstract the complicated flow of a HTR system. It's responsible for:\n",
    "\n",
    "* Create model with Handwritten Text Recognition flow, in which calculate the loss function by CTC and decode output to calculate the HTR metrics (CER, WER and SER);\n",
    "\n",
    "* Save and load model;\n",
    "\n",
    "* Load weights in the models (train/infer);\n",
    "\n",
    "* Make Train/Predict process using *generator*.\n",
    "\n",
    "To make a dynamic HTRModel, its parameters are the *architecture*, *input_size* and *vocab_size*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "nV0GreStISTR"
   },
   "outputs": [],
   "source": [
    "from network.model import HTRModel\n",
    "\n",
    "# create and compile HTRModel\n",
    "model = HTRModel(architecture=ARCH,\n",
    "                 input_size=IMG_SIZE,\n",
    "                 vocab_size=11031,\n",
    "                 beam_width=10,\n",
    "                 stop_tolerance=20,\n",
    "                 reduce_tolerance=15,\n",
    "                 reduce_factor=0.1)\n",
    "\n",
    "model.compile(learning_rate=0.001)\n",
    "#model.summary(output_path, \"summary.txt\")\n",
    "\n",
    "# get default callbacks and load checkpoint weights file (HDF5) if exists\n",
    "#model.load_checkpoint(target=target_path)\n",
    "\n",
    "#callbacks = model.get_callbacks(logdir=output_path, checkpoint=target_path, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1fnz0Eugqru"
   },
   "source": [
    "## 4 Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1mLOcqYgsO-"
   },
   "source": [
    "The training process is similar to the *fit()* of the Keras. After training, the information (epochs and minimum loss) is save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2P6MSoxCISlD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 22:37:13.220996: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 367072384 exceeds 10% of free system memory.\n",
      "2023-03-06 22:37:23.476807: W tensorflow/tsl/framework/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 350.07MiB (rounded to 367072512)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-03-06 22:37:23.476843: I tensorflow/tsl/framework/bfc_allocator.cc:1034] BFCAllocator dump for GPU_0_bfc\n",
      "2023-03-06 22:37:23.476863: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (256): \tTotal Chunks: 97, Chunks in use: 97. 24.2KiB allocated for chunks. 24.2KiB in use in bin. 9.5KiB client-requested in use in bin.\n",
      "2023-03-06 22:37:23.476877: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (512): \tTotal Chunks: 5, Chunks in use: 5. 2.8KiB allocated for chunks. 2.8KiB in use in bin. 2.0KiB client-requested in use in bin.\n",
      "2023-03-06 22:37:23.476887: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1024): \tTotal Chunks: 2, Chunks in use: 2. 2.2KiB allocated for chunks. 2.2KiB in use in bin. 2.0KiB client-requested in use in bin.\n",
      "2023-03-06 22:37:23.476898: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2048): \tTotal Chunks: 4, Chunks in use: 4. 12.0KiB allocated for chunks. 12.0KiB in use in bin. 12.0KiB client-requested in use in bin.\n",
      "2023-03-06 22:37:23.476910: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-06 22:37:23.476922: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-06 22:37:23.476937: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16384): \tTotal Chunks: 3, Chunks in use: 2. 56.0KiB allocated for chunks. 36.0KiB in use in bin. 36.0KiB client-requested in use in bin.\n",
      "2023-03-06 22:37:23.476950: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-06 22:37:23.476965: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (65536): \tTotal Chunks: 12, Chunks in use: 7. 1.01MiB allocated for chunks. 633.0KiB in use in bin. 587.0KiB client-requested in use in bin.\n",
      "2023-03-06 22:37:23.476979: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (131072): \tTotal Chunks: 7, Chunks in use: 6. 1.38MiB allocated for chunks. 1.19MiB in use in bin. 1.12MiB client-requested in use in bin.\n",
      "2023-03-06 22:37:23.477112: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (262144): \tTotal Chunks: 3, Chunks in use: 3. 1.00MiB allocated for chunks. 1.00MiB in use in bin. 1.00MiB client-requested in use in bin.\n",
      "2023-03-06 22:37:23.477131: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (524288): \tTotal Chunks: 1, Chunks in use: 0. 512.0KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-06 22:37:23.477144: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-06 22:37:23.477156: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-06 22:37:23.477169: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-06 22:37:23.477183: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8388608): \tTotal Chunks: 2, Chunks in use: 2. 20.44MiB allocated for chunks. 20.44MiB in use in bin. 20.44MiB client-requested in use in bin.\n",
      "2023-03-06 22:37:23.477193: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16777216): \tTotal Chunks: 1, Chunks in use: 0. 18.19MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-06 22:37:23.477204: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (33554432): \tTotal Chunks: 1, Chunks in use: 0. 54.42MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-06 22:37:23.477212: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-06 22:37:23.477220: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-06 22:37:23.477228: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-06 22:37:23.477237: I tensorflow/tsl/framework/bfc_allocator.cc:1057] Bin for 350.07MiB was 256.00MiB, Chunk State: \n",
      "2023-03-06 22:37:23.477244: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 101744640\n",
      "2023-03-06 22:37:23.477253: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584000000 of size 256 next 3\n",
      "2023-03-06 22:37:23.477260: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584000100 of size 256 next 4\n",
      "2023-03-06 22:37:23.477266: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584000200 of size 256 next 6\n",
      "2023-03-06 22:37:23.477273: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584000300 of size 256 next 7\n",
      "2023-03-06 22:37:23.477279: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584000400 of size 256 next 5\n",
      "2023-03-06 22:37:23.477285: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584000500 of size 256 next 8\n",
      "2023-03-06 22:37:23.477292: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584000600 of size 256 next 11\n",
      "2023-03-06 22:37:23.477298: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584000700 of size 256 next 12\n",
      "2023-03-06 22:37:23.477305: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584000800 of size 256 next 13\n",
      "2023-03-06 22:37:23.477311: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584000900 of size 256 next 14\n",
      "2023-03-06 22:37:23.477321: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584000a00 of size 256 next 9\n",
      "2023-03-06 22:37:23.477331: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584000b00 of size 768 next 10\n",
      "2023-03-06 22:37:23.477342: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584000e00 of size 256 next 15\n",
      "2023-03-06 22:37:23.477352: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584000f00 of size 256 next 16\n",
      "2023-03-06 22:37:23.477361: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584001000 of size 256 next 17\n",
      "2023-03-06 22:37:23.477371: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584001100 of size 256 next 18\n",
      "2023-03-06 22:37:23.477380: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584001200 of size 256 next 19\n",
      "2023-03-06 22:37:23.477387: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584001300 of size 256 next 20\n",
      "2023-03-06 22:37:23.477393: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584001400 of size 256 next 22\n",
      "2023-03-06 22:37:23.477400: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584001500 of size 256 next 23\n",
      "2023-03-06 22:37:23.477406: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584001600 of size 256 next 21\n",
      "2023-03-06 22:37:23.477413: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584001700 of size 3072 next 109\n",
      "2023-03-06 22:37:23.477419: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584002300 of size 3072 next 114\n",
      "2023-03-06 22:37:23.477426: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584002f00 of size 256 next 113\n",
      "2023-03-06 22:37:23.477433: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584003000 of size 1024 next 118\n",
      "2023-03-06 22:37:23.477440: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584003400 of size 256 next 116\n",
      "2023-03-06 22:37:23.477447: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584003500 of size 256 next 117\n",
      "2023-03-06 22:37:23.477453: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584003600 of size 3072 next 125\n",
      "2023-03-06 22:37:23.477460: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584004200 of size 3072 next 126\n",
      "2023-03-06 22:37:23.477466: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584004e00 of size 256 next 121\n",
      "2023-03-06 22:37:23.477473: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584004f00 of size 256 next 130\n",
      "2023-03-06 22:37:23.477479: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584005000 of size 512 next 131\n",
      "2023-03-06 22:37:23.477486: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584005200 of size 256 next 132\n",
      "2023-03-06 22:37:23.477492: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584005300 of size 256 next 133\n",
      "2023-03-06 22:37:23.477499: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584005400 of size 256 next 135\n",
      "2023-03-06 22:37:23.477505: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584005500 of size 256 next 136\n",
      "2023-03-06 22:37:23.477516: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584005600 of size 256 next 137\n",
      "2023-03-06 22:37:23.477525: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fb584005700 of size 20480 next 25\n",
      "2023-03-06 22:37:23.477535: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb58400a700 of size 18432 next 26\n",
      "2023-03-06 22:37:23.477545: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb58400ef00 of size 256 next 27\n",
      "2023-03-06 22:37:23.477554: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb58400f000 of size 256 next 24\n",
      "2023-03-06 22:37:23.477564: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb58400f100 of size 256 next 28\n",
      "2023-03-06 22:37:23.477573: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb58400f200 of size 256 next 31\n",
      "2023-03-06 22:37:23.477580: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb58400f300 of size 256 next 32\n",
      "2023-03-06 22:37:23.477586: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb58400f400 of size 256 next 33\n",
      "2023-03-06 22:37:23.477593: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb58400f500 of size 256 next 34\n",
      "2023-03-06 22:37:23.477599: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb58400f600 of size 256 next 35\n",
      "2023-03-06 22:37:23.477606: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb58400f700 of size 256 next 36\n",
      "2023-03-06 22:37:23.477612: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb58400f800 of size 256 next 37\n",
      "2023-03-06 22:37:23.477618: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb58400f900 of size 256 next 38\n",
      "2023-03-06 22:37:23.477625: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb58400fa00 of size 256 next 41\n",
      "2023-03-06 22:37:23.477631: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb58400fb00 of size 256 next 39\n",
      "2023-03-06 22:37:23.477638: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb58400fc00 of size 256 next 40\n",
      "2023-03-06 22:37:23.477644: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb58400fd00 of size 256 next 46\n",
      "2023-03-06 22:37:23.477651: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb58400fe00 of size 256 next 44\n",
      "2023-03-06 22:37:23.477992: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb58400ff00 of size 256 next 45\n",
      "2023-03-06 22:37:23.478002: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584010000 of size 256 next 47\n",
      "2023-03-06 22:37:23.478010: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584010100 of size 256 next 49\n",
      "2023-03-06 22:37:23.478017: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584010200 of size 256 next 50\n",
      "2023-03-06 22:37:23.478024: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584010300 of size 256 next 51\n",
      "2023-03-06 22:37:23.478030: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584010400 of size 256 next 52\n",
      "2023-03-06 22:37:23.478038: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584010500 of size 256 next 53\n",
      "2023-03-06 22:37:23.478048: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584010600 of size 256 next 54\n",
      "2023-03-06 22:37:23.478058: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584010700 of size 256 next 55\n",
      "2023-03-06 22:37:23.478070: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584010800 of size 512 next 58\n",
      "2023-03-06 22:37:23.478082: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584010a00 of size 256 next 56\n",
      "2023-03-06 22:37:23.478093: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584010b00 of size 256 next 57\n",
      "2023-03-06 22:37:23.478102: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584010c00 of size 256 next 61\n",
      "2023-03-06 22:37:23.478111: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584010d00 of size 256 next 62\n",
      "2023-03-06 22:37:23.478123: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584010e00 of size 256 next 65\n",
      "2023-03-06 22:37:23.478134: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584010f00 of size 256 next 66\n",
      "2023-03-06 22:37:23.478145: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584011000 of size 256 next 67\n",
      "2023-03-06 22:37:23.478156: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584011100 of size 256 next 68\n",
      "2023-03-06 22:37:23.478167: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584011200 of size 256 next 69\n",
      "2023-03-06 22:37:23.478178: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584011300 of size 256 next 70\n",
      "2023-03-06 22:37:23.478189: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584011400 of size 256 next 71\n",
      "2023-03-06 22:37:23.478201: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584011500 of size 256 next 72\n",
      "2023-03-06 22:37:23.478212: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584011600 of size 256 next 73\n",
      "2023-03-06 22:37:23.478223: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584011700 of size 512 next 76\n",
      "2023-03-06 22:37:23.478239: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584011900 of size 256 next 74\n",
      "2023-03-06 22:37:23.478252: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584011a00 of size 256 next 75\n",
      "2023-03-06 22:37:23.478263: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584011b00 of size 256 next 78\n",
      "2023-03-06 22:37:23.478274: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584011c00 of size 256 next 79\n",
      "2023-03-06 22:37:23.478285: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584011d00 of size 256 next 82\n",
      "2023-03-06 22:37:23.478296: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584011e00 of size 256 next 83\n",
      "2023-03-06 22:37:23.478307: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584011f00 of size 256 next 84\n",
      "2023-03-06 22:37:23.478318: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584012000 of size 256 next 85\n",
      "2023-03-06 22:37:23.478329: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584012100 of size 256 next 86\n",
      "2023-03-06 22:37:23.478340: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584012200 of size 256 next 87\n",
      "2023-03-06 22:37:23.478351: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584012300 of size 256 next 88\n",
      "2023-03-06 22:37:23.478363: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584012400 of size 256 next 89\n",
      "2023-03-06 22:37:23.478375: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584012500 of size 256 next 90\n",
      "2023-03-06 22:37:23.478386: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584012600 of size 512 next 91\n",
      "2023-03-06 22:37:23.478397: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584012800 of size 256 next 92\n",
      "2023-03-06 22:37:23.478408: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584012900 of size 256 next 95\n",
      "2023-03-06 22:37:23.478420: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584012a00 of size 256 next 96\n",
      "2023-03-06 22:37:23.478431: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584012b00 of size 256 next 97\n",
      "2023-03-06 22:37:23.478442: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584012c00 of size 256 next 99\n",
      "2023-03-06 22:37:23.478453: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584012d00 of size 256 next 100\n",
      "2023-03-06 22:37:23.478464: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584012e00 of size 256 next 101\n",
      "2023-03-06 22:37:23.478475: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584012f00 of size 256 next 102\n",
      "2023-03-06 22:37:23.478485: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584013000 of size 256 next 103\n",
      "2023-03-06 22:37:23.478497: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584013100 of size 256 next 104\n",
      "2023-03-06 22:37:23.478507: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584013200 of size 256 next 105\n",
      "2023-03-06 22:37:23.478518: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584013300 of size 256 next 106\n",
      "2023-03-06 22:37:23.478530: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584013400 of size 256 next 107\n",
      "2023-03-06 22:37:23.478541: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584013500 of size 256 next 110\n",
      "2023-03-06 22:37:23.478552: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584013600 of size 256 next 108\n",
      "2023-03-06 22:37:23.478564: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584013700 of size 256 next 29\n",
      "2023-03-06 22:37:23.478575: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584013800 of size 18432 next 30\n",
      "2023-03-06 22:37:23.478586: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fb584018000 of size 81920 next 48\n",
      "2023-03-06 22:37:23.478597: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb58402c000 of size 65536 next 43\n",
      "2023-03-06 22:37:23.478609: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb58403c000 of size 73728 next 42\n",
      "2023-03-06 22:37:23.478620: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fb58404e000 of size 69120 next 64\n",
      "2023-03-06 22:37:23.478630: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb58405ee00 of size 69120 next 63\n",
      "2023-03-06 22:37:23.478642: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fb58406fc00 of size 92160 next 60\n",
      "2023-03-06 22:37:23.478653: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584086400 of size 115200 next 59\n",
      "2023-03-06 22:37:23.478665: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fb5840a2600 of size 86016 next 81\n",
      "2023-03-06 22:37:23.478676: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb5840b7600 of size 86016 next 80\n",
      "2023-03-06 22:37:23.478687: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb5840cc600 of size 237824 next 1\n",
      "2023-03-06 22:37:23.478698: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584106700 of size 1280 next 2\n",
      "2023-03-06 22:37:23.478710: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584106c00 of size 165888 next 77\n",
      "2023-03-06 22:37:23.478722: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb58412f400 of size 225792 next 94\n",
      "2023-03-06 22:37:23.478733: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb584166600 of size 225792 next 93\n",
      "2023-03-06 22:37:23.478747: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb58419d800 of size 129024 next 98\n",
      "2023-03-06 22:37:23.478760: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fb5841bd000 of size 524288 next 120\n",
      "2023-03-06 22:37:23.478772: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb58423d000 of size 262144 next 119\n",
      "2023-03-06 22:37:23.478784: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb58427d000 of size 196608 next 122\n",
      "2023-03-06 22:37:23.478796: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fb5842ad000 of size 87040 next 134\n",
      "2023-03-06 22:37:23.478808: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb5842c2400 of size 109568 next 124\n",
      "2023-03-06 22:37:23.478819: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb5842dd000 of size 393216 next 123\n",
      "2023-03-06 22:37:23.478831: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb58433d000 of size 196608 next 129\n",
      "2023-03-06 22:37:23.478842: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fb58436d000 of size 196608 next 128\n",
      "2023-03-06 22:37:23.478853: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb58439d000 of size 393216 next 127\n",
      "2023-03-06 22:37:23.478865: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fb5843fd000 of size 19070976 next 111\n",
      "2023-03-06 22:37:23.478876: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb58562d000 of size 10715136 next 112\n",
      "2023-03-06 22:37:23.478887: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fb586065000 of size 10715136 next 115\n",
      "2023-03-06 22:37:23.478976: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fb586a9d000 of size 57061376 next 18446744073709551615\n",
      "2023-03-06 22:37:23.478989: I tensorflow/tsl/framework/bfc_allocator.cc:1095]      Summary of in-use Chunks by size: \n",
      "2023-03-06 22:37:23.479006: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 97 Chunks of size 256 totalling 24.2KiB\n",
      "2023-03-06 22:37:23.479020: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 4 Chunks of size 512 totalling 2.0KiB\n",
      "2023-03-06 22:37:23.479033: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 768 totalling 768B\n",
      "2023-03-06 22:37:23.479045: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1024 totalling 1.0KiB\n",
      "2023-03-06 22:37:23.479058: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-03-06 22:37:23.479071: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 4 Chunks of size 3072 totalling 12.0KiB\n",
      "2023-03-06 22:37:23.479084: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 18432 totalling 36.0KiB\n",
      "2023-03-06 22:37:23.479097: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 65536 totalling 64.0KiB\n",
      "2023-03-06 22:37:23.479111: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 69120 totalling 67.5KiB\n",
      "2023-03-06 22:37:23.479124: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 73728 totalling 72.0KiB\n",
      "2023-03-06 22:37:23.479137: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 86016 totalling 84.0KiB\n",
      "2023-03-06 22:37:23.479150: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 109568 totalling 107.0KiB\n",
      "2023-03-06 22:37:23.479163: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 115200 totalling 112.5KiB\n",
      "2023-03-06 22:37:23.479176: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 129024 totalling 126.0KiB\n",
      "2023-03-06 22:37:23.479189: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 165888 totalling 162.0KiB\n",
      "2023-03-06 22:37:23.479202: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 196608 totalling 384.0KiB\n",
      "2023-03-06 22:37:23.479215: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 225792 totalling 441.0KiB\n",
      "2023-03-06 22:37:23.479228: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 237824 totalling 232.2KiB\n",
      "2023-03-06 22:37:23.479243: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 262144 totalling 256.0KiB\n",
      "2023-03-06 22:37:23.479256: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 393216 totalling 768.0KiB\n",
      "2023-03-06 22:37:23.479269: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 10715136 totalling 20.44MiB\n",
      "2023-03-06 22:37:23.479282: I tensorflow/tsl/framework/bfc_allocator.cc:1102] Sum Total of in-use chunks: 23.32MiB\n",
      "2023-03-06 22:37:23.479295: I tensorflow/tsl/framework/bfc_allocator.cc:1104] total_region_allocated_bytes_: 101744640 memory_limit_: 113049600 available bytes: 11304960 curr_region_allocation_bytes_: 226099200\n",
      "2023-03-06 22:37:23.479312: I tensorflow/tsl/framework/bfc_allocator.cc:1110] Stats: \n",
      "Limit:                       113049600\n",
      "InUse:                        24454656\n",
      "MaxInUse:                     82972928\n",
      "NumAllocs:                         301\n",
      "MaxAllocSize:                 57061376\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-03-06 22:37:23.479336: W tensorflow/tsl/framework/bfc_allocator.cc:492] *****_________________**********************________________________________________________________\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# to calculate total and average time per epoch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#start_time = datetime.datetime.now()\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_datagen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m              \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m              \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03mtotal_time = datetime.datetime.now() - start_time\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m \n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ocr/src/network/model.py:195\u001b[0m, in \u001b[0;36mHTRModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callbacks \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_schedule:\n\u001b[1;32m    193\u001b[0m     callbacks \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m callbacks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, ReduceLROnPlateau)]\n\u001b[0;32m--> 195\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m                     \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m                     \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "# to calculate total and average time per epoch\n",
    "#start_time = datetime.datetime.now()\n",
    "\n",
    "h = model.fit(x=train_datagen,\n",
    "              epochs=EPOCHS,\n",
    "              verbose=1)\n",
    "\n",
    "'''\n",
    "total_time = datetime.datetime.now() - start_time\n",
    "\n",
    "loss = h.history['loss']\n",
    "val_loss = h.history['val_loss']\n",
    "\n",
    "min_val_loss = min(val_loss)\n",
    "min_val_loss_i = val_loss.index(min_val_loss)\n",
    "\n",
    "time_epoch = (total_time / len(loss))\n",
    "total_item = (dtgen.size['train'] + dtgen.size['valid'])\n",
    "\n",
    "t_corpus = \"\\n\".join([\n",
    "    f\"Total train images:      {dtgen.size['train']}\",\n",
    "    f\"Total validation images: {dtgen.size['valid']}\",\n",
    "    f\"Batch:                   {dtgen.batch_size}\\n\",\n",
    "    f\"Total time:              {total_time}\",\n",
    "    f\"Time per epoch:          {time_epoch}\",\n",
    "    f\"Time per item:           {time_epoch / total_item}\\n\",\n",
    "    f\"Total epochs:            {len(loss)}\",\n",
    "    f\"Best epoch               {min_val_loss_i + 1}\\n\",\n",
    "    f\"Training loss:           {loss[min_val_loss_i]:.8f}\",\n",
    "    f\"Validation loss:         {min_val_loss:.8f}\"\n",
    "])\n",
    "\n",
    "with open(os.path.join(output_path, \"train.txt\"), \"w\") as lg:\n",
    "    lg.write(t_corpus)\n",
    "    print(t_corpus)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13g7tDjWgtXV"
   },
   "source": [
    "## 5 Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddO26OT-g_QK"
   },
   "source": [
    "The predict process is similar to the *predict* of the Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_datagen,ground_truth = DataGen(valid_data, IMG_SIZE, 8, mode=\"VALID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a9iHL6tmaL_j"
   },
   "outputs": [],
   "source": [
    "from data import preproc as pp\n",
    "#from google.colab.patches import cv2_imshow\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# predict() function will return the predicts with the probabilities\n",
    "predicts, _ = model.predict(valid_data,\n",
    "                            verbose=1)\n",
    "\n",
    "# decode to string\n",
    "'''\n",
    "predicts = [dtgen.tokenizer.decode(x[0]) for x in predicts]\n",
    "ground_truth = [x.decode() for x in dtgen.dataset['test']['gt']]\n",
    "'''\n",
    "total_time = datetime.datetime.now() - start_time\n",
    "\n",
    "# mount predict corpus file\n",
    "with open(os.path.join(output_path, \"predict.txt\"), \"w\") as lg:\n",
    "    for pd, gt in zip(predicts, ground_truth):\n",
    "        lg.write(f\"TE_L {gt}\\nTE_P {pd}\\n\")\n",
    "   \n",
    "for i, item in enumerate(dtgen.dataset['test']['dt'][:10]):\n",
    "    print(\"=\" * 1024, \"\\n\")\n",
    "    cv2_imshow(pp.adjust_to_see(item))\n",
    "    print(ground_truth[i])\n",
    "    print(predicts[i], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9JcAs3Q3WNJ-"
   },
   "source": [
    "## 6 Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8LuZBRepWbom"
   },
   "source": [
    "Evaluation process is more manual process. Here we have the `ocr_metrics`, but feel free to implement other metrics instead. In the function, we have three parameters: \n",
    "\n",
    "* predicts\n",
    "* ground_truth\n",
    "* norm_accentuation (calculation with/without accentuation)\n",
    "* norm_punctuation (calculation with/without punctuation marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0gCwEYdKWOPK"
   },
   "outputs": [],
   "source": [
    "from data import evaluation\n",
    "\n",
    "evaluate = evaluation.ocr_metrics(predicts, ground_truth)\n",
    "\n",
    "e_corpus = \"\\n\".join([\n",
    "    f\"Total test images:    {dtgen.size['test']}\",\n",
    "    f\"Total time:           {total_time}\",\n",
    "    f\"Time per item:        {total_time / dtgen.size['test']}\\n\",\n",
    "    f\"Metrics:\",\n",
    "    f\"Character Error Rate: {evaluate[0]:.8f}\",\n",
    "    f\"Word Error Rate:      {evaluate[1]:.8f}\",\n",
    "    f\"Sequence Error Rate:  {evaluate[2]:.8f}\"\n",
    "])\n",
    "\n",
    "with open(os.path.join(output_path, \"evaluate.txt\"), \"w\") as lg:\n",
    "    lg.write(e_corpus)\n",
    "    print(e_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "oMty1YwuWHpN"
   ],
   "name": "tutorial.ipynb",
   "provenance": []
  },
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "vscode": {
   "interpreter": {
    "hash": "60890892eea6c86700db8a9ea51fde16553fd89a361df4a47f1b0097d87b1a20"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
